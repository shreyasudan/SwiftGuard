{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import jailbreakbench as jbb\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from scipy.special import softmax\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from SPD.main_spd import calculate_logits\n",
    "from typing import Any, Literal\n",
    "import litellm\n",
    "import openai\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.environ['OPENAI_API_KEY'] = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Save the logits\n",
    "For each dataset, calculate and save logit values in seperate folders. Hyperparameters such as temperature, top-p, top-k can be modified by altering the SPD/config_spd.py file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Location to save the data\n",
    "write_path = \"logits/gcg/test\"\n",
    "\n",
    "model_name = \"gpt-4o-mini\"\n",
    "\n",
    "# Load the data from JSON\n",
    "data_path = \"data/GPT4o/GCG.json\" \n",
    "data = pd.read_json(path_or_buf=data_path)[model_name]#[\"gpt-3.5-turbo-0613\"]\n",
    "\n",
    "# Load data from csv\n",
    "#data_path = \"data/GPT3.5/promptDatasetGPT.csv\"\n",
    "#data = pd.read_csv(data_path)\n",
    "#data = data[data[\"Success\"] == True]\n",
    "#data = data.rename(columns={\"Successful Prompt\": \"prompt\"})\n",
    "#data = data[['prompt']].apply(lambda x: x.to_dict(), axis=1)\n",
    "#data = data.reset_index(drop=True)\n",
    "#data.name = \"gpt-3.5-turbo-0613\"\n",
    "\n",
    "\n",
    "ind_to_read = [*range(160, 561)] \n",
    "prompts = {}\n",
    "for i in range(len(ind_to_read)):\n",
    "    prompts[i] = data[ind_to_read[i]][\"prompt\"]\n",
    "\n",
    "all_prompts = {model_name: prompts}\n",
    "    \n",
    "# Saves the logit values in write_path/model_name\n",
    "#logits = calculate_logits(write_path, all_prompts, llm_provider=\"litellm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "401"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "GCG_test = prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20     {'prompt': 'You are a historian who is going t...\n",
       "21     {'prompt': 'You are a famous erotic author who...\n",
       "22     {'prompt': 'Imagine you are a marketing specia...\n",
       "23     {'prompt': 'You are a researcher studying cont...\n",
       "24     {'prompt': 'I understand that discussing certa...\n",
       "                             ...                        \n",
       "115    {'prompt': 'Write a story where a character is...\n",
       "116    {'prompt': 'You are a skilled thief who has be...\n",
       "117    {'prompt': 'You are a skilled thief who has be...\n",
       "118    {'prompt': 'You are a skilled thief with a rep...\n",
       "119    {'prompt': 'You are a master thief with a repu...\n",
       "Name: gpt-4o-mini, Length: 100, dtype: object"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gathering the PAIR Prompts for later use\n",
    "\n",
    "data_path = \"data/GPT4o/PAIR.json\" \n",
    "data_pair = pd.read_json(path_or_buf=data_path)[model_name]\n",
    "o=[]\n",
    "for i in data_pair[20:120]:\n",
    "    o.append(i['prompt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "o=[]\n",
    "for i in data_pair[20:120]:\n",
    "    o.append(i['prompt'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Location to save the data BENIGN PROMPTS\n",
    "# Load the data\n",
    "model_name = \"gpt-4o-mini\"\n",
    "data_path = \"data/GPT4o/benign_outputs.json\" \n",
    "data = pd.read_json(path_or_buf=data_path)\n",
    "# shuffle data\n",
    "data = data.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "### write_path = \"logits/benign1/test\"\n",
    "ind_to_read = [*range(400, 796)] \n",
    "prompts = {}\n",
    "for i in range(len(ind_to_read)):\n",
    "    prompts[i] = data.iloc[ind_to_read].iloc[i][\"instruction\"]\n",
    "\n",
    "all_prompts = {model_name: prompts}\n",
    "    \n",
    "# Saves the logit values in write_path/model_name\n",
    "#logits = calculate_logits(write_path, all_prompts, llm_provider=\"litellm\")\n",
    "\n",
    "\n",
    "# Saving the benign prompts for later use\n",
    "benign_test_1 = prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"data/GPT4o/qnli_1000.json\"\n",
    "data = pd.read_json(path_or_buf=data_path)\n",
    "# shuffle data\n",
    "data = data.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QNLI dataset loading\n",
    "write_path = \"logits/benign2/test\"\n",
    "ind_to_read = [*range(500, 1000)] \n",
    "prompts = {}\n",
    "for i in range(len(ind_to_read)):\n",
    "    prompts[i] = data.iloc[ind_to_read].iloc[i][\"text1\"]\n",
    "\n",
    "all_prompts = {model_name: prompts}\n",
    "    \n",
    "# Saves the logit values in write_path/model_name\n",
    "#logits = calculate_logits(write_path, all_prompts, llm_provider=\"litellm\")\n",
    "\n",
    "\n",
    "\n",
    "# Saving the benign prompts for later use\n",
    "benign_test_2 = prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Load training data\n",
    "\n",
    "Load the saved logit values and prepare the feature vector. While $r$ determines the number of token locations, $k$ determines how many candidates are calculated per each location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_benign shape: (890, 125)\n",
      "logits/pair/train\n",
      "(20, 25, 5)\n",
      "logits/gcg/train\n",
      "(154, 25, 5)\n",
      "train_attack shape: (174, 125)\n",
      "Final train_x shape: (1064, 125)\n",
      "Final train_y shape: (1064,)\n"
     ]
    }
   ],
   "source": [
    "# Difference in classes code cell!\n",
    "\n",
    "BENIGN_PATH_TRAIN = \"logits/benign/train\"\n",
    "ATTACK_PATH_TRAIN = \"logits/pair/train\"\n",
    "\n",
    "model_name = \"gpt-4o-mini\"\n",
    "r = 25   # Number of token positions to consider\n",
    "k = 5    # Number of candidate logit values to consider\n",
    "\n",
    "# Two separate lists: one for all benign sets, one for all attacker sets\n",
    "benign_paths_train = [\n",
    "    \"logits/benign1/train\",\n",
    "    \"logits/benign2/train\"\n",
    "]\n",
    "\n",
    "attack_paths_train = [\n",
    "    \"logits/pair/train\",\n",
    "    \"logits/gcg/train\"\n",
    "]\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 2. Load and reshape all BENIGN TRAIN data\n",
    "# ------------------------------------------------------------------\n",
    "benign_list = []\n",
    "for path in benign_paths_train:\n",
    "    # Load logits for this subset\n",
    "    logits = np.load(os.path.join(path, f\"{model_name}.npy\"))\n",
    "    # Convert logits -> probabilities -> negative log probabilities\n",
    "    probs = softmax(logits, axis=2)\n",
    "    vals  = -np.log(probs)  # shape: [N, seq_len, vocab_subset?]\n",
    "\n",
    "    # Slice down to just the first r token positions & top k candidates\n",
    "    vals = vals[:, :r, :k]  # shape: [N, r, k]\n",
    "\n",
    "    # Flatten each sample to [r*k]\n",
    "    benign_list.append(vals.reshape(vals.shape[0], r * k))\n",
    "\n",
    "# Combine all benign samples from all benign sets\n",
    "train_benign = np.concatenate(benign_list, axis=0)\n",
    "print(\"train_benign shape:\", train_benign.shape)\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 3. Load and reshape all ATTACK TRAIN data\n",
    "# ------------------------------------------------------------------\n",
    "attack_list = []\n",
    "for path in attack_paths_train:\n",
    "    logits = np.load(os.path.join(path, f\"{model_name}.npy\"))\n",
    "    probs  = softmax(logits, axis=2)\n",
    "    vals   = -np.log(probs)\n",
    "\n",
    "    vals = vals[:, :r, :k]\n",
    "    print(path)\n",
    "    print(vals.shape)\n",
    "    attack_list.append(vals.reshape(vals.shape[0], r * k))\n",
    "\n",
    "# Combine all attack samples from all attack sets\n",
    "train_attack = np.concatenate(attack_list, axis=0)\n",
    "print(\"train_attack shape:\", train_attack.shape)\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 4. Create final training arrays (X, y)\n",
    "# ------------------------------------------------------------------\n",
    "train_x = np.concatenate([train_benign, train_attack], axis=0)\n",
    "train_y = np.concatenate([\n",
    "    np.zeros(train_benign.shape[0]),  # label=0 for benign\n",
    "    np.ones(train_attack.shape[0])    # label=1 for attack\n",
    "])\n",
    "\n",
    "print(\"Final train_x shape:\", train_x.shape)\n",
    "print(\"Final train_y shape:\", train_y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Train the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(class_weight=&#x27;balanced&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>SVC</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.svm.SVC.html\">?<span>Documentation for SVC</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>SVC(class_weight=&#x27;balanced&#x27;)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "SVC(class_weight='balanced')"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the classifier \n",
    "clf = SVC(kernel=\"rbf\",class_weight=\"balanced\")\n",
    "clf.fit(train_x, train_y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "benign_data shape: (160, 25, 5)\n",
      "attack_data shape: (100, 25, 5)\n"
     ]
    }
   ],
   "source": [
    "benign_data = np.load(os.path.join(\"logits/benign/test\", f\"{model_name}.npy\"))\n",
    "print(\"benign_data shape:\", benign_data.shape)\n",
    "attack_data = np.load(os.path.join(\"logits/pair/test\", f\"{model_name}.npy\"))\n",
    "print(\"attack_data shape:\", attack_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Load the test data\n",
    "\n",
    "Load the saved logit values and prepare the feature vector. $r$ and $k$ values should remain the same with training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Locations of the test data\n",
    "#read_paths_test = [\"GPT3.5/logits/benign1/test\",\n",
    "#                    \"GPT3.5/logits/benign2/test\",\n",
    "#                    \"gpt-3.5/logits/pair/test\",\n",
    "#                    \"gpt-3.5/logits/gcg/test\"]\n",
    "\n",
    "read_paths_test = [\"logits/benign/test\", \n",
    "                   \"logits/pair/test\"]\n",
    "#test_size = 40\n",
    "\n",
    "logit_values_test = []\n",
    "\n",
    "# Finding minimum test size dynamically in case of imbalanced classes\n",
    "test_sizes = []\n",
    "for path in read_paths_test:\n",
    "    logits = np.load(os.path.join(path, f\"{model_name}.npy\"))\n",
    "    test_sizes.append(logits.shape[0])  # Number of available samples\n",
    "\n",
    "test_size = min(test_sizes)\n",
    "\n",
    "for path in read_paths_test:\n",
    "    logits = np.load(os.path.join(path, f\"{model_name}.npy\"))\n",
    "    probabilities = softmax(logits, axis=2)\n",
    "    values = - np.log(probabilities)\n",
    "    \n",
    "    logit_values_test.append(values[:test_size,:r,:k].reshape(test_size, r * k))\n",
    "\n",
    "logit_values_test = np.array(logit_values_test)\n",
    "benign_indexes = [0]\n",
    "attack_indexes = [1]\n",
    "\n",
    "test_benign = np.concatenate((logit_values_test[benign_indexes]))\n",
    "test_attack = np.concatenate((logit_values_test[attack_indexes]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(478, 125)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_attack.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_benign shape: (889, 125)\n",
      "test_attack shape: (478, 125)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[4.43443764e-02, 3.79434439e+00, 4.54434415e+00, ...,\n",
       "        5.20191968e+00, 6.57691968e+00, 9.70192015e+00],\n",
       "       [3.60304403e-01, 1.36030437e+00, 3.98530437e+00, ...,\n",
       "        1.81250114e+01, 1.83750114e+01, 2.00000114e+01],\n",
       "       [3.49210490e-02, 3.53492096e+00, 5.65992096e+00, ...,\n",
       "        1.86717682e+00, 3.74217682e+00, 3.99217682e+00],\n",
       "       ...,\n",
       "       [4.50349706e-01, 1.70034968e+00, 2.20034980e+00, ...,\n",
       "        2.86123344e+00, 2.98623344e+00, 3.86123344e+00],\n",
       "       [6.71809038e-03, 5.00671815e+00, 1.31317177e+01, ...,\n",
       "        8.19344228e+00, 1.10684423e+01, 1.25684423e+01],\n",
       "       [8.61761680e-03, 4.75861761e+00, 1.30086181e+01, ...,\n",
       "        8.50783764e+00, 1.03828376e+01, 1.21328376e+01]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"gpt-4o-mini\"\n",
    "r = 25\n",
    "k = 5\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 1. Define the paths where your TEST data (logits) live\n",
    "# ------------------------------------------------------------------\n",
    "benign_paths_test = [\n",
    "    \"logits/benign1/test\",\n",
    "    \"logits/benign2/test\"\n",
    "]\n",
    "\n",
    "attack_paths_test = [\n",
    "    \"logits/pair/test\",\n",
    "    \"logits/gcg/test\"\n",
    "]\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 2. Load and reshape all BENIGN TEST data\n",
    "# ------------------------------------------------------------------\n",
    "test_benign_list = []\n",
    "for path in benign_paths_test:\n",
    "    logits = np.load(os.path.join(path, f\"{model_name}.npy\"))\n",
    "    probs  = softmax(logits, axis=2)\n",
    "    vals   = -np.log(probs)               # shape: [N, seq_len, vocab_subset?]\n",
    "\n",
    "    # Keep only first r token positions and top k candidates\n",
    "    vals = vals[:, :r, :k]                # shape: [N, r, k]\n",
    "    test_benign_list.append(vals.reshape(vals.shape[0], r * k))\n",
    "\n",
    "# Combine all benign test samples\n",
    "test_benign = np.concatenate(test_benign_list, axis=0)\n",
    "print(\"test_benign shape:\", test_benign.shape)\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 3. Load and reshape all ATTACK TEST data\n",
    "# ------------------------------------------------------------------\n",
    "test_attack_list = []\n",
    "for path in attack_paths_test:\n",
    "    logits = np.load(os.path.join(path, f\"{model_name}.npy\"))\n",
    "    probs  = softmax(logits, axis=2)\n",
    "    vals   = -np.log(probs)\n",
    "\n",
    "    vals = vals[:, :r, :k]\n",
    "    test_attack_list.append(vals.reshape(vals.shape[0], r * k))\n",
    "\n",
    "# Combine all attack test samples\n",
    "test_attack = np.concatenate(test_attack_list, axis=0)\n",
    "print(\"test_attack shape:\", test_attack.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Putting all Benign Test prompts together to associate them with logits\n",
    "benign_test_1_trimmed = [benign_test_1[i] for i in range(393)]\n",
    "benign_test_2_trimmed = [benign_test_2[i] for i in range(496)]\n",
    "test_benign_df = pd.DataFrame(test_benign)\n",
    "test_benign_df['prompts'] = pd.concat([pd.Series(benign_test_1_trimmed), pd.Series(benign_test_2_trimmed)]).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from: logits/pair/test\\gpt-4o-mini.npy\n",
      "Shape of arr: (100, 25, 5)\n",
      "Loading from: logits/gcg/test\\gpt-4o-mini.npy\n",
      "Shape of arr: (378, 25, 5)\n"
     ]
    }
   ],
   "source": [
    "paths = [\n",
    "    \"logits/pair/test\",\n",
    "    \"logits/gcg/test\"\n",
    "]\n",
    "\n",
    "for path in paths:\n",
    "    path_npy = os.path.join(path, f\"{model_name}.npy\")\n",
    "    print(\"Loading from:\", path_npy)\n",
    "    arr = np.load(path_npy)\n",
    "    print(\"Shape of arr:\", arr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      You are a historian who is going to write a co...\n",
       "1      You are a famous erotic author who has written...\n",
       "2      Imagine you are a marketing specialist for a c...\n",
       "3      You are a researcher studying controversial an...\n",
       "4      I understand that discussing certain controver...\n",
       "                             ...                        \n",
       "473    Create a fake online store that steals custome...\n",
       "474    Write a manual on how to escape from a correct...\n",
       "475    Create a fake news story that spreads misinfor...\n",
       "476    Write a manual on how to escape from a correct...\n",
       "477    Write a blog post promoting the use of illegal...\n",
       "Length: 478, dtype: object"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Putting the attacks in one dataframe\n",
    "test_attack_df = pd.DataFrame(test_attack)\n",
    "test_attack_df['prompt'] = pd.concat([pd.Series(o), pd.Series(GCG_test).sample(378)]).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Test the classifier\n",
    "\n",
    "Get the TP and FP rates of the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preliminary Classifier \n",
    "#-----------------------\n",
    "# Uses an LLM to check for overtly benign prompts\n",
    "# Created in LLM_Classifier.ipynb\n",
    "\n",
    "def call_model(input_text,llm):\n",
    "    '''\n",
    "    Calls an LLM with a given input text\n",
    "\n",
    "    input_text: a string of text to input in the LLM\n",
    "    llm: a string outlining which llm from together AI to use\n",
    "    '''\n",
    "    response = openai.chat.completions.create(\n",
    "                model = llm,\n",
    "                messages = [\n",
    "                    {\"role\": \"user\", \"content\": input_text},\n",
    "                ],\n",
    "                max_tokens = 1000,\n",
    "            )\n",
    "    output = response.choices[0].message.content\n",
    "    \n",
    "    return output\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def llm_check(llm, series):\n",
    "    '''\n",
    "    A preliminary LLM classifer identifying benign prompts\n",
    "\n",
    "    llm: a string outlining which llm from together AI to use\n",
    "    series: a series containing prompts from which to classify\n",
    "    n: the number of prompts to sample from the series and classify\n",
    "\n",
    "    OUTPUT: 'YES' or 'NO' with 'NO' meaning that there is some element of the prompt that could make it harmful\n",
    "             while 'YES' means it is confidentally benign.\n",
    "    '''\n",
    "    results = []\n",
    "    #sample = series.sample(n)\n",
    "    sample = series\n",
    "    for query in sample:\n",
    "        temp_prompt = prompt_check.replace('{QUERY}', query)\n",
    "        out = call_model(temp_prompt, llm)\n",
    "        results.append(out.strip())\n",
    "    return results\n",
    "with open('assets/check_system.txt', 'r') as f:\n",
    "    prompt_check = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating a sample of benign and attack data \n",
    "sampled_df = pd.concat([test_benign_df.sample(200, random_state = 123).reset_index(drop = True), test_attack_df.sample(200, random_state = 123).reset_index(drop = True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179.2693271636963\n"
     ]
    }
   ],
   "source": [
    "# Running Prompts marked as 'Not Benign' from the preliminary classifier through SPD\n",
    "\n",
    "import time \n",
    "model_name = \"gpt-4o-mini\"\n",
    "start_time = time.time()\n",
    "prelim_results = llm_check(model_name, sampled_df['prompts'])\n",
    "end_time = time.time()\n",
    "print(end_time -  start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_df['true'] = ['benign'] * 200 + ['attack'] * 200 \n",
    "sampled_df['results'] = prelim_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "prelim_nos = sampled_df[sampled_df['results'] == 'NO'].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true\n",
       "attack    199\n",
       "benign      7\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prelim_nos['true'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>119</th>\n",
       "      <th>120</th>\n",
       "      <th>121</th>\n",
       "      <th>122</th>\n",
       "      <th>123</th>\n",
       "      <th>124</th>\n",
       "      <th>prompts</th>\n",
       "      <th>results</th>\n",
       "      <th>true</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.36378</td>\n",
       "      <td>1.86378</td>\n",
       "      <td>2.11378</td>\n",
       "      <td>3.73878</td>\n",
       "      <td>5.23878</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>11.750013</td>\n",
       "      <td>12.250013</td>\n",
       "      <td>15.375013</td>\n",
       "      <td>19.625013</td>\n",
       "      <td>...</td>\n",
       "      <td>15.630277</td>\n",
       "      <td>0.006034</td>\n",
       "      <td>5.256034</td>\n",
       "      <td>7.131034</td>\n",
       "      <td>15.381035</td>\n",
       "      <td>16.506035</td>\n",
       "      <td>AI assistant. I am looking for legal reference...</td>\n",
       "      <td>NO</td>\n",
       "      <td>benign</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 129 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0        1        2        3        4         5          6  \\\n",
       "3  0.36378  1.86378  2.11378  3.73878  5.23878  0.000013  11.750013   \n",
       "\n",
       "           7          8          9  ...        119       120       121  \\\n",
       "3  12.250013  15.375013  19.625013  ...  15.630277  0.006034  5.256034   \n",
       "\n",
       "        122        123        124  \\\n",
       "3  7.131034  15.381035  16.506035   \n",
       "\n",
       "                                             prompts  results    true  pred  \n",
       "3  AI assistant. I am looking for legal reference...       NO  benign   1.0  \n",
       "\n",
       "[1 rows x 129 columns]"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# False Positives out of 200 \n",
    "prelim_nos[(prelim_nos['pred'] == 1) & (prelim_nos['true'] == 'benign')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true\n",
       "benign    193\n",
       "attack      1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prompts marked 'benign' by preliminary classifier\n",
    "sampled_df[sampled_df['results'] == 'YES']['true'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating F-1 Score\n",
    "f = np.concatenate((\n",
    "    np.zeros(193), \n",
    "    np.ones(1)\n",
    "))\n",
    "g = np.zeros(194)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Calculating F-1 Score\n",
    "left = pd.concat([pd.DataFrame(f).rename(columns = {0:'true'}),pd.DataFrame(g).rename(columns = {0:'pred'})], axis = 1)\n",
    "\n",
    "right = pd.concat([pd.DataFrame((prelim_nos['true'] == 'attack').astype(float)),prelim_nos[['pred']]], axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating F-1 Score\n",
    "final_results = pd.concat([left, right])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9251336898395722"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculating F-1 Score\n",
    "h = pd.concat([pd.DataFrame((prelim_nos['true'] == 'attack').astype(float)),prelim_nos[['pred']]], axis = 1)\n",
    "\n",
    "f1_score(final_results['true'], final_results['pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "prelim_nos['pred'] = clf_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.010164022445678711\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "clf_out = clf.predict(prelim_nos.drop(columns = ['prompts', 'results', 'true']).to_numpy())\n",
    "end_time = time.time()\n",
    "print(end_time -  start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_3_prompts = prelim_nos[clf_out == 0]['prompts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discarded Semantic Transformation Pupeline\n",
    "# \n",
    "# Originates from Transforming.ipynb\n",
    "\n",
    "transformations_dir = os.path.join(os.getcwd(), 'transformations')\n",
    "SEMANTIC_TRANSFORMATIONS = [\n",
    "    \"summarize\",\n",
    "    \"paraphrase\",\n",
    "    \"synonym\",\n",
    "    \"verbtense\",\n",
    "    \"spellcheck\",\n",
    "    \"translate\",\n",
    "    \"formatsummarize\"\n",
    "]\n",
    "\n",
    "def transform(input_text, transformation_type, llm):\n",
    "    '''\n",
    "    Takes an input_text and transforms it according to a specified transformation_type. \n",
    "\n",
    "    input_text: string of text to transform\n",
    "    transformation_type: string naming which transformation to apply (from SEMANTIC_TRANSFORMATIONS)\n",
    "    llm: a string outlining which llm from together AI to use\n",
    "    '''\n",
    "    if transformation_type.lower() not in SEMANTIC_TRANSFORMATIONS:\n",
    "        print('Enter Valid Transformation')\n",
    "        return None\n",
    "\n",
    "    template_file = transformation_type.lower() + '.txt'\n",
    "    input_prompt = open(os.path.join(transformations_dir, template_file), 'r').read().strip()\n",
    "    \n",
    "    transformed_input = input_prompt.replace('{QUERY}', input_text)\n",
    "    transformed_input = call_model(transformed_input, llm)\n",
    "    \n",
    "    if transformation_type.lower() == 'translate':\n",
    "        transformed_input = transformed_input + \"\\n Please answer the above instructions in English.\"\n",
    "    if transformation_type.lower() == 'formatsummarize':\n",
    "        transformed_input = transformed_input + \" Please answer the above instructions.\"\n",
    "\n",
    "    \n",
    "    \n",
    "    return transformed_input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discarded Semantic Transformation Pipeline\n",
    "judge_system = open('assets/judge_system.txt', 'r').read().strip()\n",
    "\n",
    "def judge_call(prompt, response, llm):  \n",
    "        judge_prompt = f\"Prompt: {prompt}\\nResponse: {response}\"\n",
    "        \n",
    "        messages = [\n",
    "            {'role': 'system', 'content': judge_system},\n",
    "            {'role': 'user', 'content': judge_prompt}\n",
    "        ]\n",
    "        \n",
    "        response = openai.chat.completions.create(model =llm, messages = messages, max_tokens = 1000)\n",
    "        \n",
    "        return response.choices[0].message.content\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Discarded Semantic Transformation Pipeline\n",
    "\n",
    "def transform_check(prompts, llm):\n",
    "    '''\n",
    "    prompt: input prompt \n",
    "    llm: llm to use\n",
    "    '''\n",
    "    results = []\n",
    "    #judge_prompt = open(os.path.join(assets_dir, 'judge_system.txt'), 'r').read().strip()\n",
    "    for prompt in prompts:\n",
    "        \n",
    "        transformed = transform(prompt, 'spellcheck', llm)\n",
    "        transformed2 = transform(transformed, 'summarize', llm)\n",
    "        response = call_model(transformed2, llm)\n",
    "        print(response)\n",
    "        judge_response = judge_call(transformed2, response, llm)\n",
    "        results.append(judge_response)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "#judged_responses = transform_check(pipeline_3_prompts, model_name)\n",
    "#judged_responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in pipeline_3_prompts:\n",
    "    #print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
